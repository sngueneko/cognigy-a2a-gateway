# ğŸ¤– Cognigy A2A Gateway

A **production-grade Agent-to-Agent (A2A) protocol gateway** that exposes [Cognigy.AI](https://cognigy.com/) conversational flows as fully compliant A2A agents. Any A2A-compatible client â€” Azure AI Foundry, Microsoft Copilot Studio, LangChain, AutoGen, or any custom agent â€” can discover and call your Cognigy bots without writing a single line of Cognigy-specific integration code.

Built with **TypeScript 5**, **Express 5**, **@a2a-js/sdk 0.3.10**, and **@cognigy/socket-client 4.9**.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Environment Variables](#-environment-variables)
- [HTTP API Reference](#-http-api-reference)
- [REST vs SOCKET: Message vs Task](#-rest-vs-socket-message-vs-task)
- [Adapters In Depth](#-adapters-in-depth)
  - [IAdapter â€” Strategy Interface](#iadapter--strategy-interface)
  - [RestAdapter](#restadapter)
  - [SocketAdapter](#socketadapter)
  - [SocketConnectionPool](#socketconnectionpool)
- [Output Normalization](#-output-normalization)
  - [Event Routing: StatusMessage vs Artifact](#event-routing-statusmessage-vs-artifact)
  - [Human Text Generation](#human-text-generation)
  - [DataPart Preservation](#datapart-preservation)
  - [MIME Type Inference](#mime-type-inference)
  - [Adaptive Card Extraction](#adaptive-card-extraction)
- [Request Lifecycle](#-request-lifecycle)
- [Getting Started](#-getting-started)
- [Build](#-build)
- [Running](#-running)
- [ğŸ³ Docker Deployment](#-docker-deployment)
- [Testing](#-testing)
- [Azure AI Foundry Integration](#-azure-ai-foundry-integration)
- [Extending the Gateway](#-extending-the-gateway)
- [Logging](#-logging)
- [Roadmap](#-roadmap)

---

## ğŸŒ Overview

The gateway sits between **any A2A client** and **Cognigy.AI**, translating the open A2A JSON-RPC protocol into Cognigy's proprietary REST or Socket communication.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        A2A JSON-RPC (HTTP)        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Any A2A Client         â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                                     â”‚
â”‚                          â”‚                                    â”‚     Cognigy A2A Gateway             â”‚
â”‚  â€¢ Azure AI Foundry      â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                                     â”‚
â”‚  â€¢ Copilot Studio        â”‚        A2A JSON-RPC Response       â”‚  AgentRegistry â†’ AgentExecutor      â”‚
â”‚  â€¢ LangChain / AutoGen   â”‚                                    â”‚       â†“                â†“            â”‚
â”‚  â€¢ Custom curl / app     â”‚                                    â”‚  RestAdapter    SocketAdapter       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚       â†“                â†“            â”‚
                                                                â”‚  Cognigy REST   Cognigy Socket      â”‚
                                                                â”‚  Endpoint       Endpoint            â”‚
                                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âœ¨ Key Features

- **Dual transport** â€” REST (synchronous) and Socket.IO (async/agentic, streaming, multi-turn) endpoints
- **Multi-agent** â€” configure N independent agents, each with its own endpoint and skills
- **Full A2A compliance** â€” AgentCard discovery, JSON-RPC 2.0 message protocol, task lifecycle events, spec v0.3.0
- **Task-aware execution** â€” tracks in-flight tasks with `TaskSessionRegistry`; correct event sequences per adapter type; supports task cancellation
- **Output normalization** â€” all Cognigy rich output types (quick replies, gallery, buttons, lists, Adaptive Cards, image, audio, video) are automatically converted to A2A events with correct routing per type
- **Dual A2A event routing** â€” conversational outputs â†’ `TaskStatusUpdateEvent` with human-readable `TextPart` + structured `DataPart`; media outputs â†’ `TaskArtifactUpdateEvent` with `FilePart` + MIME type
- **MIME type inference** â€” image/audio/video MIME types automatically inferred from URL extension
- **Internal metadata filtering** â€” Cognigy's `_cognigy` metadata entries are stripped transparently
- **Socket connection pool** â€” persistent Socket.IO connections with exponential-backoff reconnect, idle-close, and per-session isolation
- **Structured logging** â€” pino JSON logs with AWS CloudWatch-compatible format
- **ENV substitution** â€” secrets never in config files; all values resolved from environment variables at startup
- **Docker-ready** â€” multi-stage production `Dockerfile` + `docker-compose.yml` with Redis profile

---

## ğŸ— Architecture

### Component Map

```
src/
â”œâ”€â”€ index.ts                    # Express bootstrap â€” registers all routes
â”œâ”€â”€ registry/
â”‚   â””â”€â”€ AgentRegistry.ts        # Loads config, builds AgentCards, O(1) lookup
â”œâ”€â”€ config/
â”‚   â””â”€â”€ loader.ts               # Reads agents.config.json, resolves ${ENV} vars
â”œâ”€â”€ handlers/
â”‚   â””â”€â”€ CognigyAgentExecutor.ts # A2A AgentExecutor â€” task-aware, routes NormalizedOutput to correct event type
â”œâ”€â”€ task/
â”‚   â”œâ”€â”€ TaskSessionRegistry.ts  # In-flight task tracker (AbortController per taskId)
â”‚   â””â”€â”€ TaskStoreFactory.ts     # Task store factory (memory default, Redis optional)
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ IAdapter.ts             # Strategy interface + OutputCallback for streaming
â”‚   â”œâ”€â”€ RestAdapter.ts          # HTTP POST via axios â†’ Cognigy REST endpoint
â”‚   â””â”€â”€ SocketAdapter.ts        # Socket.IO per-session client â†’ streams via OutputCallback
â”œâ”€â”€ pool/
â”‚   â””â”€â”€ SocketConnectionPool.ts # Persistent connection lifecycle manager
â”œâ”€â”€ normalizer/
â”‚   â””â”€â”€ OutputNormalizer.ts     # Cognigy outputStack[] â†’ NormalizedOutput (StatusMessage | Artifact)
â”œâ”€â”€ types/
â”‚   â”œâ”€â”€ agent.types.ts          # Config schema types + A2A AgentCard types
â”‚   â””â”€â”€ cognigy.types.ts        # Cognigy output types + type guards (incl. image/audio/video)
â””â”€â”€ logger.ts                   # pino structured logger
```

### Data Flow (per request)

#### REST adapter â€” synchronous (no streaming)

```
POST /agents/{id}/
        â”‚
        â–¼
  @a2a-js/sdk jsonRpcHandler          â† validates JSON-RPC envelope
        â”‚
        â–¼
  CognigyAgentExecutor.execute()
        â”‚
        â””â”€ RestAdapter.send()
                â”‚  POST <endpointUrl>/<urlToken>
                â”‚  â† CognigyRestResponse { outputStack[] }
                â”‚  filter isCognigyInternalEntry()
                â””â”€â–º CognigyBaseOutput[]
        â”‚
        â–¼
  normalizeOutputs(outputs)            â† flattens all NormalizedOutput.parts into Part[]
        â–¼
  Message { parts: Part[] }            â”€â”€â–º eventBus.publish()
  eventBus.finished()
```

#### SOCKET adapter â€” true streaming with event routing

```
POST /agents/{id}/
        â”‚
        â–¼
  @a2a-js/sdk jsonRpcHandler
        â”‚
        â–¼
  CognigyAgentExecutor.execute()
        â”‚
        â”œâ”€ TaskStatusUpdateEvent { state:'working', final:false }  â”€â”€â–º eventBus
        â”‚
        â””â”€ SocketAdapter.send({ onOutput })
                â”‚  connect â†’ sendMessage
                â”‚
                â”‚  Cognigy 'output' event â†’ onOutput(output, i) â†’ normalizeOutput(output)
                â”‚
                â”‚    if NormalizedOutput.kind === 'status-message':
                â”‚      â””â”€â–º TaskStatusUpdateEvent { state:'working', message:{parts} } â”€â”€â–º eventBus
                â”‚
                â”‚    if NormalizedOutput.kind === 'artifact':
                â”‚      â””â”€â–º TaskArtifactUpdateEvent { artifact:{FilePart, TextPart} } â”€â”€â–º eventBus
                â”‚
                â””â”€ Cognigy 'finalPing' â†’ Promise resolves
        â”‚
        â–¼
  TaskStatusUpdateEvent { state:'completed', final:true }  â”€â”€â–º eventBus
  eventBus.finished()
```

**A2A event sequence for SOCKET agents:**

| # | Event | `final` | Description |
|---|---|---|---|
| 1 | `TaskStatusUpdateEvent` `working` (no message) | `false` | Task opened |
| 2â€¦N | `TaskStatusUpdateEvent` `working` + `message` | `false` | Per conversational output (text, quick replies, etc.) |
| 2â€¦N | `TaskArtifactUpdateEvent` | â€” | Per media output (image, audio, video) |
| N+1 | `TaskStatusUpdateEvent` `completed` | `true` | Task closed â€” stream ends |

**Terminal status states:**

| Scenario | `state` |
|---|---|
| Flow completed normally | `completed` |
| Task cancelled | `canceled` |
| Adapter error / exception | `failed` |

---

## ğŸ“ Project Structure

```
cognigy-a2a-gateway/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ IAdapter.ts
â”‚   â”‚   â”œâ”€â”€ RestAdapter.ts
â”‚   â”‚   â””â”€â”€ SocketAdapter.ts
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ loader.ts
â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â””â”€â”€ CognigyAgentExecutor.ts
â”‚   â”œâ”€â”€ task/
â”‚   â”‚   â”œâ”€â”€ TaskSessionRegistry.ts
â”‚   â”‚   â””â”€â”€ TaskStoreFactory.ts
â”‚   â”œâ”€â”€ normalizer/
â”‚   â”‚   â””â”€â”€ OutputNormalizer.ts
â”‚   â”œâ”€â”€ pool/
â”‚   â”‚   â””â”€â”€ SocketConnectionPool.ts
â”‚   â”œâ”€â”€ registry/
â”‚   â”‚   â””â”€â”€ AgentRegistry.ts
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ agent.types.ts
â”‚   â”‚   â””â”€â”€ cognigy.types.ts
â”‚   â”œâ”€â”€ index.ts
â”‚   â””â”€â”€ logger.ts
â”œâ”€â”€ tests/                               # Mirrors src/ structure
â”œâ”€â”€ agents.config.json                   # Agent definitions
â”œâ”€â”€ .env.example                         # Environment variable template
â”œâ”€â”€ Dockerfile                           # Multi-stage production image
â”œâ”€â”€ docker-compose.yml                   # Compose: gateway + optional Redis
â”œâ”€â”€ jest.config.ts
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

---

## âš™ï¸ Configuration

### `agents.config.json`

This file is the **single source of truth** for all agents served by the gateway. It is loaded once at startup. All string values support `${ENV_VAR}` substitution â€” secrets are never hardcoded.

```json
{
  "agents": [
    {
      "id": "faq-agent",
      "name": "FAQ Assistant",
      "description": "Answers frequently asked questions using a synchronous Cognigy REST endpoint.",
      "version": "1.0.0",
      "endpointType": "REST",
      "endpointUrl": "${COGNIGY_FAQ_URL}",
      "urlToken": "${COGNIGY_FAQ_TOKEN}",
      "skills": [
        {
          "id": "faq",
          "name": "FAQ",
          "description": "Answer product and service questions",
          "tags": ["faq", "support", "knowledge-base"]
        }
      ]
    },
    {
      "id": "booking-agent",
      "name": "Booking Assistant",
      "description": "Handles flight and hotel bookings using an agentic Cognigy flow.",
      "version": "1.0.0",
      "endpointType": "SOCKET",
      "endpointUrl": "${COGNIGY_BOOKING_URL}",
      "urlToken": "${COGNIGY_BOOKING_TOKEN}",
      "skills": [
        {
          "id": "booking",
          "name": "Travel Booking",
          "description": "Book flights, hotels, and rental cars",
          "tags": ["booking", "travel", "flights", "hotels"]
        }
      ]
    }
  ]
}
```

#### Field Reference

| Field | Type | Required | Description |
|---|---|---|---|
| `id` | `string` | âœ… | Unique agent identifier. Used in URL paths (`/agents/{id}/`). Must be URL-safe. |
| `name` | `string` | âœ… | Human-readable display name included in the AgentCard. |
| `description` | `string` | âœ… | Agent description included in the AgentCard. |
| `version` | `string` | âœ… | Agent version string (e.g. `"1.0.0"`). |
| `endpointType` | `"REST" \| "SOCKET"` | âœ… | Determines which adapter handles requests for this agent. |
| `endpointUrl` | `string` | âœ… | Cognigy endpoint base URL (e.g. `https://endpoint.cognigy.ai`). |
| `urlToken` | `string` | âœ… | Cognigy URL token. Appended as a path segment: `<endpointUrl>/<urlToken>`. |
| `skills[].id` | `string` | âœ… | Skill identifier used by A2A orchestrators to route requests. |
| `skills[].name` | `string` | âœ… | Human-readable skill name. |
| `skills[].description` | `string` | âœ… | Skill description used by AI clients for intent routing. |
| `skills[].tags` | `string[]` | âœ… | Searchable tags for skill discovery. |

> ğŸ’¡ **How `urlToken` is used:** For `REST`, the final request URL is `POST <endpointUrl>/<urlToken>`. For `SOCKET`, the token is passed as the second argument to `new SocketClient(endpointUrl, urlToken, ...)`.

---

## ğŸ” Environment Variables

Copy `.env.example` to `.env` and fill in your values before running locally.

```bash
cp .env.example .env
```

| Variable | Required | Default | Description |
|---|---|---|---|
| `PORT` | âŒ | `3000` | HTTP port the Express server listens on. |
| `LOG_LEVEL` | âŒ | `info` | Pino log level: `trace`, `debug`, `info`, `warn`, `error`. |
| `LOG_PRETTY` | âŒ | `false` | Set to `true` for colored human-readable logs (development only). |
| `NODE_ENV` | âŒ | `development` | Included in all log entries for environment context. |
| `AGENTS_CONFIG_PATH` | âŒ | `./agents.config.json` | Absolute or relative path to the agents config file. |
| `TASK_STORE_TYPE` | âŒ | `memory` | Task store backend. `memory` (default) or `redis`. |
| `TASK_STORE_REDIS_URL` | âŒ* | `redis://localhost:6379` | Redis connection URL. Required when `TASK_STORE_TYPE=redis`. |
| `TASK_STORE_REDIS_TTL_S` | âŒ | `3600` | Task TTL in Redis (seconds). |
| `TASK_STORE_REDIS_PREFIX` | âŒ | `a2a:task:` | Key prefix for task entries in Redis. |
| `COGNIGY_FAQ_URL` | âœ…* | â€” | Referenced by `agents.config.json` via `${COGNIGY_FAQ_URL}`. |
| `COGNIGY_FAQ_TOKEN` | âœ…* | â€” | Referenced by `agents.config.json` via `${COGNIGY_FAQ_TOKEN}`. |
| `COGNIGY_BOOKING_URL` | âœ…* | â€” | Referenced by `agents.config.json` via `${COGNIGY_BOOKING_URL}`. |
| `COGNIGY_BOOKING_TOKEN` | âœ…* | â€” | Referenced by `agents.config.json` via `${COGNIGY_BOOKING_TOKEN}`. |

> âœ…* = required if your `agents.config.json` references that variable. Any `${VAR}` placeholder that resolves to an empty or missing env var causes a `ConfigurationError` at startup.

---

## ğŸŒ HTTP API Reference

Once running, the gateway exposes the following endpoints:

### Discovery

| Method | Path | Description |
|---|---|---|
| `GET` | `/.well-known/agents.json` | Returns an array of all registered AgentCards. |
| `GET` | `/agents` | Alias for `/.well-known/agents.json`. |
| `GET` | `/agents/:id/.well-known/agent-card.json` | Returns the AgentCard for a specific agent (A2A spec Â§3.1). |

### Invocation

| Method | Path | Description |
|---|---|---|
| `POST` | `/agents/:id/` | A2A JSON-RPC 2.0 endpoint. Send messages, receive agent responses. |

### Utility

| Method | Path | Description |
|---|---|---|
| `GET` | `/health` | Health check. Returns `{ "status": "healthy", "agents": N, "timestamp": "..." }`. |

### Example A2A Request / Response

**Request:**
```http
POST /agents/faq-agent/
Content-Type: application/json

{
  "jsonrpc": "2.0",
  "method": "message/send",
  "id": "req-001",
  "params": {
    "message": {
      "kind": "message",
      "messageId": "msg-uuid-1234",
      "role": "user",
      "contextId": "session-abc-xyz",
      "parts": [
        { "kind": "text", "text": "What is your return policy?" }
      ]
    }
  }
}
```

**Response:**
```json
{
  "jsonrpc": "2.0",
  "id": "req-001",
  "result": {
    "kind": "message",
    "messageId": "resp-uuid-5678",
    "role": "agent",
    "contextId": "session-abc-xyz",
    "parts": [
      { "kind": "text", "text": "You can return items within 30 days of purchase with a receipt." }
    ]
  }
}
```

> ğŸ’¡ **Multi-turn conversations:** Keep `contextId` stable across all turns. The gateway maps `contextId` â†’ `sessionId` in Cognigy, so Cognigy maintains conversation context automatically.

---

## ğŸ“¬ REST vs SOCKET: Message vs Task

This is a fundamental design distinction in the gateway. The two adapter types produce **different A2A response patterns**.

### REST â†’ delivers a `Message` directly

REST is synchronous. You send a request, Cognigy processes it, all outputs come back at once. The A2A `Message` is sufficient â€” no task lifecycle needed.

The client receives exactly **1 event**: the final `Message` containing all parts flattened together (including any FilePart for media outputs, since streaming is not available on REST).

### SOCKET â†’ wraps everything in a `Task` with event routing

SOCKET is asynchronous and streaming. The executor routes each `NormalizedOutput` to the correct A2A event type as it arrives:

```
TaskStatusUpdateEvent { state:'working', final:false }     â† task opened

  â€” conversational outputs get status-update events with message parts â€”
TaskStatusUpdateEvent { state:'working', message:{parts}, final:false }   â† text / quick replies / buttons / etc.

  â€” media outputs get artifact-update events â€”
TaskArtifactUpdateEvent { artifact:{ FilePart, TextPart } }               â† image / audio / video

TaskStatusUpdateEvent { state:'completed', final:true }    â† task closed
```

### Quick comparison

| | REST | SOCKET |
|---|---|---|
| **Use for** | FAQ, lookup, simple Q&A | Booking, workflows, agentic flows |
| **Response model** | `Message` only | `Task` with status + artifact streaming |
| **Conversational outputs** | `Message.parts[]` | `TaskStatusUpdateEvent` + `message.parts[]` |
| **Media outputs** | `Message.parts[]` (inline FilePart) | `TaskArtifactUpdateEvent` with FilePart |
| **Streaming** | âŒ No | âœ… Yes, per Cognigy output |
| **Cancellable** | âŒ No | âœ… Yes, via `TaskSessionRegistry` |
| **Max wait time** | 8 seconds | 60 seconds |

---

## ğŸ”Œ Adapters In Depth

The gateway uses the **Strategy Pattern** for Cognigy communication. Both adapters implement the same `IAdapter` interface, and `CognigyAgentExecutor` selects the correct one at construction time based on `endpointType`.

### IAdapter â€” Strategy Interface

```typescript
/** Called by SocketAdapter for each Cognigy output event as it arrives, before finalPing. */
export type OutputCallback = (output: CognigyBaseOutput, index: number) => void;

interface IAdapter {
  readonly type: 'REST' | 'SOCKET';
  send(params: AdapterSendParams): Promise<ReadonlyArray<CognigyBaseOutput>>;
}

interface AdapterSendParams {
  readonly text: string;
  readonly sessionId: string;
  readonly userId: string;
  readonly data?: Record<string, unknown>;
  readonly onOutput?: OutputCallback;       // Streaming callback (SocketAdapter only)
}
```

Both adapters throw `AdapterError` on failure, carrying `adapterType` and the original `cause`.

---

### RestAdapter

**Use when:** Your Cognigy flow is a standard synchronous REST endpoint. Best for FAQs, simple Q&A, lookup flows where response time is under 8 seconds.

#### Timeout & Error Handling

| Scenario | Behavior |
|---|---|
| Response received within 8s | âœ… Returns filtered `outputStack[]` |
| No response within 8s | âŒ `AdapterError`: "timed out after 8000ms" |
| HTTP 4xx/5xx | âŒ `AdapterError`: "failed with HTTP {status}" |
| Network failure | âŒ `AdapterError`: "failed with unexpected error" |

---

### SocketAdapter

**Use when:** Your Cognigy flow is an **agentic / multi-step** flow that requires streaming outputs or longer processing times. Best for booking assistants, complex workflows.

The SocketAdapter unwraps Cognigy's `data._cognigy._default.<type>` envelope so OutputNormalizer receives the payload at the top level. It also detects media data fields (`_image`, `_audio`, `_video`) in `message.data` and emits them as separate outputs.

#### Session Lifecycle & Timeout

```
connect() â”€â”€â–º sendMessage() â”€â”€â–º [output events...] â”€â”€â–º finalPing â”€â”€â–º disconnect()
                                      â”‚
                              60s timeout guard
```

---

### SocketConnectionPool

A **singleton** that manages long-lived agent-level `SocketClient` connections with exponential-backoff reconnect and 5-minute idle disconnect.

#### Reconnect Policy

| Attempt | Delay (with Â±20% jitter) |
|---|---|
| 1 | ~1s |
| 2 | ~2s |
| 3 | ~4s |
| 4 | ~8s |
| 5 | ~16s |
| 6 | ~30s (max) |

After 6 failed attempts â†’ **DEAD**. Auth errors (401/403) â†’ **immediate DEAD**, no retries.

---

## ğŸ”„ Output Normalization

`OutputNormalizer` converts every Cognigy output into a typed `NormalizedOutput` discriminated union, and `CognigyAgentExecutor` routes it to the correct A2A event type.

### Event Routing: StatusMessage vs Artifact

The normalizer returns one of two shapes:

```typescript
// Conversational output â†’ rides in TaskStatusUpdateEvent.status.message
interface StatusMessageOutput {
  kind: 'status-message';
  parts: Part[];           // [TextPart, DataPart?]
}

// Binary media output â†’ rides in TaskArtifactUpdateEvent.artifact
interface ArtifactOutput {
  kind: 'artifact';
  parts: Part[];           // [FilePart, TextPart]
  mimeType: string;        // inferred from URL extension
  name: string;            // filename extracted from URL
  fileUrl: string;
}
```

The executor checks `normalized.kind` and publishes accordingly:

```
kind === 'status-message'
  â†’ TaskStatusUpdateEvent { state:'working', message:{ parts } }

kind === 'artifact'
  â†’ TaskArtifactUpdateEvent { artifact:{ name, parts:[FilePart, TextPart] } }
```

### Human Text Generation

Every output type always produces at least one `TextPart` â€” ensuring text-only A2A clients (including pure LLM agents) always get a readable response, regardless of the Cognigy output type.

| Cognigy Output Type | TextPart content |
|---|---|
| Plain text | `output.text` verbatim |
| `_quickReplies` | Label + `- <title> ![image](<imageUrl>)` per option (imageUrl if non-empty) |
| `_buttons` | Label + `- <title>` / `- <title>: <url>` for `web_url` type buttons |
| `_list` | Header + `- <title>: <subtitle> ![image](<imageUrl>)` per item (imageUrl if non-empty) |
| `_gallery` | `output.text` (or "Here are some options:") + `- <title>: <subtitle> ![image](<imageUrl>)` per card |
| `_adaptiveCard` | All TextBlocks + FactSet rows + Input labels + Action titles (see below) |
| Custom data with `_fallbackText` | `_fallbackText` value |
| Custom data without `_fallbackText` | *(empty TextPart)* |
| Image | `[Image: <url>]` |
| Audio | `[Audio: <url>]` |
| Video | `[Video: <url>]` |

#### Gallery intro sentence

Gallery outputs use `output.text` as the intro sentence when present. When `output.text` is null (Cognigy sends `text: null` alongside the gallery payload), the intro defaults to `"Here are some options:"`. This ensures LLM agents always receive a complete, grammatically correct description.

### DataPart Preservation

For all structured types, the original Cognigy payload is preserved verbatim in a `DataPart`. Downstream agents that understand Cognigy formats can read the full payload; agents that don't simply ignore it.

```json
{
  "kind": "data",
  "data": {
    "type": "quick_replies",
    "payload": {
      "text": "Choose your topic",
      "quickReplies": [
        { "title": "Billing", "payload": "billing" },
        { "title": "Technical Support", "payload": "tech" }
      ]
    }
  }
}
```

| Cognigy Type | DataPart `type` field |
|---|---|
| `_quickReplies` | `quick_replies` |
| `_gallery` | `carousel` |
| `_buttons` | `buttons` |
| `_list` | `list` |
| `_adaptiveCard` | `AdaptiveCard` |
| Custom data | `cognigy/data` |
| Image / Audio / Video | *(no DataPart â€” `FilePart` instead)* |

Cognigy-internal keys (`_fallbackText`, `_cognigy`) are stripped before the DataPart is created.

### MIME Type Inference

Image, audio, and video outputs include a `FilePart` with the media URL and an inferred MIME type based on the URL file extension:

| Category | Supported extensions |
|---|---|
| Image | `jpg`, `jpeg`, `png`, `gif`, `webp`, `svg`, `bmp`, `ico` |
| Audio | `mp3`, `ogg`, `wav`, `m4a`, `aac`, `flac`, `webm` |
| Video | `mp4`, `webm`, `ogg`, `avi`, `mov`, `mkv`, `m4v` |

Unknown extensions fall back to `image/jpeg`, `audio/mpeg`, or `video/mp4` respectively. Query strings are stripped before extension detection.

### Adaptive Card Extraction

The Adaptive Card renderer performs a **recursive deep extraction** across all known card element types, producing a single readable text block that an LLM agent can interpret without knowledge of the Adaptive Card schema:

| Element type | Extracted content |
|---|---|
| `TextBlock` | `.text` value |
| `FactSet` | `"<title>: <value>"` per fact |
| `Input.Text`, `Input.Date`, `Input.Number`, `Input.Time` | Label + placeholder |
| `Input.ChoiceSet` | Label + `"- <title>"` per choice |
| `Input.Toggle` | `.title` text |
| `ColumnSet` | Recurses into `columns[].items` |
| `Container` | Recurses into `items` |
| `Action.*` | `"[Action: <title>]"` |

This means an LLM agent reading the TextPart from an Adaptive Card can see both the card's displayed content (TextBlocks) and understand what inputs/choices it is presenting to the user (Input fields, choices, actions).

---

## ğŸš€ Getting Started

### Prerequisites

| Tool | Minimum Version |
|---|---|
| Node.js | **22.x** |
| npm | **10.x** |
| A Cognigy.AI account | â€” |

### Step 1 â€” Clone and install

```bash
git clone https://github.com/your-org/cognigy-a2a-gateway.git
cd cognigy-a2a-gateway/gateway
npm install
```

### Step 2 â€” Configure environment

```bash
cp .env.example .env
```

Edit `.env` with your Cognigy endpoint URLs and tokens.

> ğŸ”‘ Find your endpoint URL in Cognigy.AI under **Deploy â†’ Endpoints â†’ {your endpoint} â†’ Endpoint URL**. The URL looks like `https://endpoint.cognigy.ai/abc123` â€” the base URL is `https://endpoint.cognigy.ai` and `abc123` is the token.

### Step 3 â€” Start in development mode

```bash
npm run dev
```

### Step 4 â€” Verify

```bash
curl http://localhost:3000/health
curl http://localhost:3000/.well-known/agents.json
```

---

## ğŸ”¨ Build

```bash
# Type-check only (fast CI check â€” no output files)
npm run build:check

# Full compile to dist/
npm run build

# Clean + rebuild
npm run clean && npm run build
```

---

## â–¶ï¸ Running

### Development (hot-reload)

```bash
npm run dev
```

### Production (Node.js)

```bash
npm run build
node dist/index.js
```

### Production (Docker)

See the [Docker Deployment](#-docker-deployment) section below.

---

## ğŸ³ Docker Deployment

The gateway ships with a production-grade multi-stage `Dockerfile` and a `docker-compose.yml` supporting two deployment modes:

| Mode | Command | When to use |
|---|---|---|
| Gateway only (memory store) | `docker compose up` | Single instance, dev/staging |
| Gateway + Redis | `docker compose --profile redis up` | Multi-replica, persistent task state |

### Step 1 â€” Create your env file

```bash
cp .env.example .env.docker
```

Edit `.env.docker` with your real values:

```env
PORT=3000
LOG_LEVEL=info
LOG_PRETTY=false
TASK_STORE_TYPE=memory
COGNIGY_BOOKING_URL=https://endpoint-trial.cognigy.ai/socket/YOUR_WORKSPACE/YOUR_ENDPOINT
COGNIGY_BOOKING_TOKEN=your-booking-token-here
COGNIGY_FAQ_URL=https://endpoint-trial.cognigy.ai/YOUR_WORKSPACE/YOUR_ENDPOINT
COGNIGY_FAQ_TOKEN=your-faq-token-here
```

### Step 2 â€” Build and start

```bash
# Gateway only
docker compose --env-file .env.docker up --build

# Gateway + Redis
docker compose --env-file .env.docker --profile redis up --build -d
```

### Step 3 â€” Verify

```bash
curl http://localhost:3000/health
curl http://localhost:3000/.well-known/agents.json
```

### Common commands

```bash
docker compose --env-file .env.docker logs -f gateway
docker compose --env-file .env.docker restart gateway
docker compose --env-file .env.docker up --build -d
docker compose --env-file .env.docker down
```

---

## ğŸ§ª Testing

```bash
npm test                  # run all tests
npm run test:coverage     # with coverage report
npm run test:watch        # watch mode
```

### Test structure

| Test file | What it covers |
|---|---|
| `tests/adapters/RestAdapter.test.ts` | URL construction, internal entry filtering, timeout, HTTP errors, request body |
| `tests/adapters/SocketAdapter.test.ts` | Per-session isolation, output streaming, finalPing, timeout, disconnect |
| `tests/normalizer/OutputNormalizer.test.ts` | All output types â†’ NormalizedOutput, TextPart content, DataPart structure, MIME inference, Adaptive Card extraction |
| `tests/pool/SocketConnectionPool.test.ts` | State machine transitions, reconnect backoff, idle timeout, auth errors |
| `tests/registry/AgentRegistry.test.ts` | AgentCard generation, multi-agent lookup, URL construction |
| `tests/config/loader.test.ts` | ENV substitution, missing variable errors, JSON parse errors, duplicate IDs |
| `tests/task/TaskSessionRegistry.test.ts` | Register/deregister tasks, abort in-flight tasks, concurrent tracking |
| `tests/task/TaskStoreFactory.test.ts` | Memory store (default), Redis store selection via `TASK_STORE_TYPE` |
| `tests/handlers/CognigyAgentExecutor.test.ts` | REST vs SOCKET event sequences, status-message vs artifact routing, cancel, error, terminal states |

---

## â˜ï¸ Azure AI Foundry Integration

In **Azure AI Foundry** â†’ your project â†’ **Agents** â†’ **Connected agents** â†’ paste the AgentCard URL:

```
https://your-apim.azure-api.net/agents/faq-agent/.well-known/agent-card.json
```

Foundry fetches the card, reads the skills, and registers Cognigy as a callable sub-agent.

---

## ğŸ§© Extending the Gateway

### Adding a new agent

Add a new entry to `agents.config.json` and provide the matching env vars. No code changes needed.

### Adding authentication

Insert an Express middleware before the JSON-RPC handler in `index.ts`:

```typescript
app.use(`/agents/${agentId}/`, (req, res, next) => {
  if (req.headers['x-api-key'] !== process.env['GATEWAY_API_KEY']) {
    return res.status(401).json({ error: 'Unauthorized' });
  }
  next();
}, jsonRpcHandler({ ... }));
```

---

## ğŸ“Š Logging

All logs are **structured JSON** using [pino](https://getpino.io/):

```json
{
  "level": "info",
  "time": "2025-01-01T12:00:00.000Z",
  "service": "cognigy-a2a-gateway",
  "env": "production",
  "component": "CognigyAgentExecutor",
  "agentId": "booking-agent",
  "taskId": "task-uuid",
  "statusMessageCount": 3,
  "artifactCount": 1,
  "durationMs": 4200,
  "event": "session.ended",
  "msg": "A2A request completed"
}
```

Set `LOG_PRETTY=true` and `LOG_LEVEL=debug` for development.

---

## ğŸ—º Roadmap

- [x] **Phase 1** â€” TypeScript project setup, config schema, ENV substitution, agent type system
- [x] **Phase 2** â€” Express server, AgentRegistry, AgentCard generation, RestAdapter, OutputNormalizer
- [x] **Phase 3** â€” SocketAdapter, SocketConnectionPool, reconnect logic, per-session isolation
- [x] **Phase 3.1** â€” Bug fixes: urlToken in RestAdapter, internal entry filtering, `_cognigy` metadata stripping
- [x] **Phase 3.2** â€” Task-aware execution: `TaskSessionRegistry`, `TaskStoreFactory`, task lifecycle status events
- [x] **Phase 3.3** â€” True A2A streaming: `OutputCallback`, `TaskArtifactUpdateEvent` per output, correct terminal states
- [x] **Phase 3.4** â€” Production Dockerfile (multi-stage, node:22-alpine), `docker-compose.yml` with Redis profile
- [x] **Phase 3.5** â€” Output normalization refactor: `NormalizedOutput` discriminated union, `StatusMessageOutput` â†’ `TaskStatusUpdateEvent`, `ArtifactOutput` â†’ `TaskArtifactUpdateEvent`, MIME type inference, full Adaptive Card extraction, image/audio/video type guards
- [ ] **Phase 5** â€” AWS CDK stacks (NetworkStack, DataStack, ComputeStack, ObservabilityStack)
- [ ] **Phase 6** â€” GitLab CI/CD pipeline (build â†’ test â†’ docker â†’ deploy)
- [ ] **Phase 7** â€” Route 53 + WAF, auto scaling, go-live

---

## ğŸ“„ License

MIT â€” see [LICENSE](../LICENSE) for details.
